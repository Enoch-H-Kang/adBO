#!/bin/bash
#SBATCH -J hotpot_gepa_cmp
#SBATCH -o %x.%j.out
#SBATCH -e %x.%j.err
#SBATCH -p mi2104x
#SBATCH -t 24:00:00
#SBATCH -N 1
#SBATCH -n 4
#SBATCH -c 12

set -euo pipefail

module purge
module load hpcfund
module load rocm/6.4.1
module list

source $WORK/venv/hotpotqa2/bin/activate

# Caches in $WORK
export HF_HOME="$WORK/adBO/cache/hf"
export HF_DATASETS_CACHE="$HF_HOME/datasets"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export HUGGINGFACE_HUB_CACHE="$HF_HOME/hub"
export XDG_CACHE_HOME="$WORK/adBO/cache/xdg"
mkdir -p "$HF_HOME" "$XDG_CACHE_HOME"

# Resume-friendly: use fixed "latest" folder instead of timestamped
OUT_ROOT="$WORK/adBO/runs/hotpotqa_runs/latest"
mkdir -p "$OUT_ROOT"

# Redirect SLURM stdout/stderr to OUT_ROOT
exec > "$OUT_ROOT/slurm_${SLURM_JOB_ID}.out" 2> "$OUT_ROOT/slurm_${SLURM_JOB_ID}.err"

# Stamp run marker so you can see last job time
date > "$OUT_ROOT/last_submit_time.txt"
echo "OUT_ROOT=$OUT_ROOT"

export VLLM_MODEL="Qwen/Qwen3-8B"
export VLLM_API_KEY="EMPTY"

# Force ROCm device detection
export VLLM_TARGET_DEVICE="rocm"

# Optional: clean restart (set CLEAN=1 when submitting)
#   CLEAN=1 sbatch job.hotpot_compare_resume.sbatch
if [[ "${CLEAN:-0}" == "1" ]]; then
  echo "[CLEAN=1] Removing previous curves/plots (keeping caches) ..."
  rm -rf "$OUT_ROOT/logs" || true
  rm -f "$OUT_ROOT/comparison_live.png" "$OUT_ROOT/comparison.png" "$OUT_ROOT/comparison_curves.csv" || true
fi

echo "==== rocm-smi (sanity) ===="
rocm-smi || true
echo "==========================="

# ----------------------------
# Pick collision-free ports (avoid 8000)
# ----------------------------
BASE_PORT=$(( 18000 + (SLURM_JOB_ID % 1000) * 10 ))
PORT0=$((BASE_PORT + 0))
PORT1=$((BASE_PORT + 1))
PORT2=$((BASE_PORT + 2))

API0="http://127.0.0.1:${PORT0}/v1"
API1="http://127.0.0.1:${PORT1}/v1"
API2="http://127.0.0.1:${PORT2}/v1"

echo "Using ports: $PORT0 $PORT1 $PORT2" | tee "$OUT_ROOT/ports.txt"
echo "$API0,$API1,$API2" > "$OUT_ROOT/api_bases.txt"

# ----------------------------
# Start 3 vLLM servers on 3 GPUs using srun
# NOTE: Use inline env var (HIP_VISIBLE_DEVICES=X srun ...) to avoid race condition
# with backgrounded commands. Using "export" before "&" causes all processes to
# potentially see the same (last) value since exports happen before sruns start.
# ----------------------------
# NOTE: Using GPUs 0, 2, 3 (skipping GPU 1 which is unreliable)
HIP_VISIBLE_DEVICES=0 srun -n 1 --exact \
  $WORK/venv/hotpotqa2/bin/vllm serve "$VLLM_MODEL" --host 127.0.0.1 --port ${PORT0} --api-key "$VLLM_API_KEY" --max-model-len 16384 -O 0 \
  >> "$OUT_ROOT/vllm_${PORT0}.log" 2>&1 &

HIP_VISIBLE_DEVICES=2 srun -n 1 --exact \
  $WORK/venv/hotpotqa2/bin/vllm serve "$VLLM_MODEL" --host 127.0.0.1 --port ${PORT1} --api-key "$VLLM_API_KEY" --max-model-len 16384 -O 0 \
  >> "$OUT_ROOT/vllm_${PORT1}.log" 2>&1 &

HIP_VISIBLE_DEVICES=3 srun -n 1 --exact \
  $WORK/venv/hotpotqa2/bin/vllm serve "$VLLM_MODEL" --host 127.0.0.1 --port ${PORT2} --api-key "$VLLM_API_KEY" --max-model-len 16384 -O 0 \
  >> "$OUT_ROOT/vllm_${PORT2}.log" 2>&1 &

# ----------------------------
# Wait for servers
# ----------------------------
echo "Waiting for vLLM servers..."
for port in "$PORT0" "$PORT1" "$PORT2"; do
  echo "  waiting on $port ..."
  for i in $(seq 1 300); do
    if curl -sf -H "Authorization: Bearer $VLLM_API_KEY" "http://127.0.0.1:${port}/v1/models" >/dev/null; then
      echo "  vLLM on ${port} is up."
      break
    fi
    sleep 2
  done
done

# quick sanity dump
echo "=== vLLM /v1/models sanity ==="
curl -sS -H "Authorization: Bearer $VLLM_API_KEY" "http://127.0.0.1:${PORT0}/v1/models" | head
curl -sS -H "Authorization: Bearer $VLLM_API_KEY" "http://127.0.0.1:${PORT1}/v1/models" | head
curl -sS -H "Authorization: Bearer $VLLM_API_KEY" "http://127.0.0.1:${PORT2}/v1/models" | head
echo "=============================="

# ----------------------------
# Run compare driver with correct api_bases
# ----------------------------
cd $WORK/adBO/hotpotqa

python run_gepa_hotpotqa_compare.py \
  --out_root "$OUT_ROOT/logs" \
  --api_bases "$API0,$API1,$API2" \
  --refresh_sec 20 \
  --stage_step 500 \
  --seed 0 \
  --max_metric_calls 10000 \
  --num_threads 12

echo "Done. Outputs in: $OUT_ROOT/logs"
